{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "358ea36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca653f7",
   "metadata": {},
   "source": [
    "# OnDeck ML Challenge\n",
    "\n",
    "This notebook is part of the [OnDeck ML Challenge](https://gist.github.com/thaumant/ea2f03b5546f36b72443357238edd2d9)\n",
    "\n",
    "- Build the first iteration of a recommender system that could suggest top-recommended movies to users.\n",
    "- Provide a GitHub repo (private is fine) with the working model and some description of how to reproduce training/testing steps.\n",
    "- Provide written answers to these questions:\n",
    "  - A brief justification of the chosen model and the scoring metric. What alternatives would be worth exploring?\n",
    "  - What would be your next steps to improve the recommendation quality?\n",
    "\n",
    "## Chosen Modeling Approaches\n",
    "\n",
    "## Scoring Metric\n",
    "\n",
    "\n",
    "For any recommendation system, we've multiple choice of a scoring or evaluation metric. We've search-inspired metrics: Hit Ratio, Precision @K, Recall @K, mean reciprocal rank, nDCG and so on. We also have regression-inspired metrics e.g. RMSE, MAE.\n",
    "\n",
    "I'm picking metrics with 2 separate intents: \n",
    "1. Modeling movie-user interaction as implicit feedback\n",
    "2. Modeling movie-user interaction as explicit feedback\n",
    "\n",
    "For comparing approaches across \n",
    "\n",
    "Metric 1 is always Hit Ratio.\n",
    "\n",
    "## Improving Recommendation Quality\n",
    "\n",
    "There are 2 main approaches for improving recommendation quality\n",
    "\n",
    "**Modeling/Algorithmic Improvements**\n",
    "\n",
    "1. In addition to SVD, other matrix factorisation methods can be looked into e.g. [ALS](https://www.elenacuoco.com/2016/12/22/alternating-least-squares-als-spark-ml/#:~:text=ALS%20recommender%20is%20a%20matrix,algorithm%20in%20a%20parallel%20fashion.) is a well-known and popular baseline which we can look into\n",
    "\n",
    "1. Parameter turning for all the approaches: While I've used a **GridSearchCV** based approach for SVD optimisation - I didn't optimise the hyperparameters for Neural Collaborative Filtering\n",
    "\n",
    "1. Better/Domain-specific Embedding: We use embedding which are trained on a large open-domain dataset ranging from Wikipedia to Reddit. Maybe, a movies specific embedding built using a Language Model trained on it would yield better similarity results.\n",
    "\n",
    "**Improve dataset usage**\n",
    "\n",
    "1. In the present implementation, I do not use the `teams` or `aggs` information at all. Using `teams`, we can exploit actor/writer/director preferences of the user, if any.\n",
    "\n",
    "1. Incorporate popular demographic information (from `aggs`) and year (from `movies`) as categorical variables which can also help improve the movie similarity recommendation\n",
    "\n",
    "1. Given any information about the user itself, e.g. the demographic - we can establish\n",
    "\n",
    "[Dataset link](https://www.dropbox.com/s/vi7lktdxx0r97o4/od-challenge.tar.gz?dl=1).\n",
    "\n",
    "## Notes\n",
    "\n",
    "- You define the technical details of the solution: the model, feature set, test/train split, normalization, loss, scoring metric.\n",
    "- You're not expected to use as much features as possible. Explore the data and take what works best for your approach.\n",
    "- You're not expected to produce a model with perfect scores. It's enough to pick a sensible model, make a few tweak iterations, produce some results, and outline a path to improve it.\n",
    "\n",
    "## Technical constraints\n",
    "\n",
    "- Python 3.6+.\n",
    "- The model, the traing and testing code should be in Jupyter notebooks. Everything else may be in notebooks or python files.\n",
    "- If trainng takes more than an hour on a laptop, provide the trained model and the code to load it.\n",
    "\n",
    "## Dataset details\n",
    "\n",
    "`movies.pickle` (4107 rows) — basic info about movies:\n",
    "\n",
    "| Column     | Type       | Example                             | Notes                     |\n",
    "| :--------- | :--------- | :---------------------------------- | :------------------------ |\n",
    "| `movie_id` | `int`      | `109830`                            |\n",
    "| `title`    | `str`      | `\"Forrest Gump\"`                    |\n",
    "| `genres`   | `set[str]` | `{\"Romance\", \"Comedy\"}`             |\n",
    "| `year`     | `int`      | `1994`                              |\n",
    "| `synopsis` | `str`      | `\"The film begins with feather...\"` | Detailed plot description |\n",
    "\n",
    "`aggs.pickle` (28557 rows) — aggregated ratings, total and by demographic:\n",
    "\n",
    "| Column           | Type    | Example       | Notes                                     |\n",
    "| :--------------- | :------ | :------------ | :---------------------------------------- |\n",
    "| `movie_id`       | `int`   | `109830`      |\n",
    "| `rating_average` | `float` | `8.8`         |\n",
    "| `rating_count`   | `int`   | `304`         | Number of ratings collected for the group |\n",
    "| `demographic`    | `str`   | `\"age_18_29\"` | Group name: total, by age, by gender      |\n",
    "\n",
    "`teams.pickle` (190547 rows) — cast & crew:\n",
    "\n",
    "| Column        | Type  | Example             | Notes                       |\n",
    "| :------------ | :---- | :------------------ | :-------------------------- |\n",
    "| `movie_id`    | `int` | `109830`            |\n",
    "| `person_role` | `str` | `\"actor\"`           | Enum: actor/director/writer |\n",
    "| `person_id`   | `int` | `37097`             |\n",
    "| `person_name` | `str` | `\"Giovanni Arpino\"` |\n",
    "\n",
    "`labels.pickle` (42237 rows) — user ratings to use as labels:\n",
    "\n",
    "| Column     | Type    | Example  | Notes      |\n",
    "| :--------- | :------ | :------- | :--------- |\n",
    "| `movie_id` | `int`   | `109830` |\n",
    "| `user_id`  | `int`   | `184`    |\n",
    "| `rating`   | `float` | `8.8`    | 1-10 scale |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d06815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import autoreload\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd02c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    url: str = \"https://www.dropbox.com/s/vi7lktdxx0r97o4/od-challenge.tar.gz?dl=1\",\n",
    "    file_name: str = \"../data/raw/od-challenge.tar.gz\",\n",
    "):\n",
    "    # Download the file from `url` and save it locally under `file_name`:\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca278327",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(\"../data/raw/od-challenge.tar.gz\") as file:\n",
    "    file.extractall(\"../data/ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901380f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/ext/od-challenge/aggs.pickle'),\n",
       " PosixPath('../data/ext/od-challenge/teams.pickle'),\n",
       " PosixPath('../data/ext/od-challenge/movies.pickle'),\n",
       " PosixPath('../data/ext/od-challenge/labels.pickle')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"../data/ext/od-challenge\")\n",
    "assert data_dir.exists()\n",
    "files = data_dir.ls()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dda5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_dir, ds: str):\n",
    "    with (data_dir / f\"{ds}.pickle\").open(\"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db496ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = read(data_dir, \"aggs\")\n",
    "teams = read(data_dir, \"teams\")\n",
    "movies = read(data_dir, \"movies\")\n",
    "labels = read(data_dir, \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be14757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4107 movies with 42237 ratings against them. There are also 610 users only\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"There are {labels.movie_id.nunique()} movies with {len(labels)} ratings against them. There are also {labels.user_id.nunique()} users only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb375c6",
   "metadata": {},
   "source": [
    "The relatively small number of user-movie ratings indicates that training a deep learning model from scratch might not be a great approach. We still have the option of using a deep learning based approaches, which don't require large amounts of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c63846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4107,\n",
       " 610,\n",
       " 4.0    11815\n",
       " 3.0     7859\n",
       " 5.0     7045\n",
       " 3.5     4784\n",
       " 4.5     3961\n",
       " 2.0     2685\n",
       " 2.5     1635\n",
       " 1.0     1219\n",
       " 0.5      669\n",
       " 1.5      565\n",
       " Name: rating, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()\n",
    "labels.movie_id.nunique(), labels.user_id.nunique(), labels.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf66e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4107,\n",
       " {Drama}                                         328\n",
       " {Comedy}                                        307\n",
       " {Comedy, Drama}                                 141\n",
       " {Romance, Drama}                                138\n",
       " {Comedy, Romance}                               137\n",
       "                                                ... \n",
       " {Horror, Fantasy, Romance, Thriller}              1\n",
       " {Fantasy, Action}                                 1\n",
       " {Thriller, Romance, Horror, Drama}                1\n",
       " {Horror, Fantasy, Crime}                          1\n",
       " {Fantasy, Sci-Fi, Adventure, Comedy, Action}      1\n",
       " Name: genres, Length: 683, dtype: int64,\n",
       " 2006    153\n",
       " 2007    149\n",
       " 2008    144\n",
       " 2005    143\n",
       " 2009    141\n",
       "        ... \n",
       " 1928      1\n",
       " 1922      1\n",
       " 1902      1\n",
       " 1924      1\n",
       " 1920      1\n",
       " Name: year, Length: 98, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()\n",
    "movies.movie_id.nunique(), movies.genres.value_counts(), movies.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f5584a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4107,\n",
       " 3,\n",
       " 107832,\n",
       " 498278     56\n",
       " 919798     55\n",
       " 168        55\n",
       " 230        52\n",
       " 134        52\n",
       "            ..\n",
       " 1295573     1\n",
       " 1005623     1\n",
       " 1296206     1\n",
       " 472790      1\n",
       " 88746       1\n",
       " Name: person_id, Length: 107832, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.head()\n",
    "teams.movie_id.nunique(), teams.person_role.nunique(), teams.person_id.nunique(), teams.person_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c51479",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = movies.genres.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23365d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Children': 316,\n",
       "         'Animation': 259,\n",
       "         'Fantasy': 419,\n",
       "         'Adventure': 744,\n",
       "         'Comedy': 1489,\n",
       "         'Thriller': 1099,\n",
       "         'Crime': 610,\n",
       "         'Action': 1055,\n",
       "         'Romance': 666,\n",
       "         'Drama': 1821,\n",
       "         'Horror': 497,\n",
       "         'Sci-Fi': 580,\n",
       "         'Mystery': 318,\n",
       "         'War': 180,\n",
       "         'IMAX': 136,\n",
       "         'Western': 74,\n",
       "         'Musical': 143,\n",
       "         'Film-Noir': 42,\n",
       "         'Documentary': 49})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_genres = []\n",
    "for g in genres:\n",
    "    flat_genres.extend(list(g))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(flat_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b8cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating_average</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>demographic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109830</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1870499</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109830</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1032446</td>\n",
       "      <td>gender_m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109830</td>\n",
       "      <td>8.7</td>\n",
       "      <td>269593</td>\n",
       "      <td>gender_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109830</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1215</td>\n",
       "      <td>age_0_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109830</td>\n",
       "      <td>8.9</td>\n",
       "      <td>344804</td>\n",
       "      <td>age_18_29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id  rating_average rating_count demographic\n",
       "0   109830             8.8      1870499       total\n",
       "1   109830             8.8      1032446    gender_m\n",
       "2   109830             8.7       269593    gender_f\n",
       "3   109830             8.9         1215    age_0_17\n",
       "4   109830             8.9       344804   age_18_29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d784f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4107"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.movie_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb99a53",
   "metadata": {},
   "source": [
    "# Possible Features for Every Movie:\n",
    "\n",
    "1. Genre (Binarized?)\n",
    "2. Year of Release (Cont.)\n",
    "3. Vector Emb of Synopsis, say 786 or 300 dim\n",
    "4. Some combination of Top_Demo * Rating_Count of Ratings Average -- captures information about \"Popular in\" what demo\n",
    "5. Preference in actor/writer/director? What about person_id? There's too many values there. Maybe retain the most popular? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0699a3",
   "metadata": {},
   "source": [
    "# How to split data?\n",
    "\n",
    "There is more than one way to think about recommending a movie. Here are few: \n",
    "\n",
    "1. Leave-one-last-out: Leave one last movie from a stream of user rated movies, and predict the next movie\n",
    "2. Random Movie: For each user, split interactions into train and test data\n",
    "3. Random User: Split some users into train, the rest into test\n",
    "4. Random Rating: Split some ratings into train, rest into test - without ensuring that a user or a movie is absent is leaking in test or not\n",
    "5. Time-based: Split within each user, based on rating timestamp\n",
    "\n",
    "Since we don't have have time of rating, we can safely ignore that. Last one out also requires making some assumption about the data ordering, so I am choosing to skip that. From the remaining options - to keep things simple, I'm choosing `Random Rating`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645e250",
   "metadata": {},
   "source": [
    "# Simple Baseline: Popular Movies\n",
    "\n",
    "\n",
    "Before we start modeling the movie-user interaction and preference, I'd like to implement a baseline approach: \n",
    "What if recommend the most popular Top 10 movies to every user? When measuring popularity, we're looking for movies which are rated often - independent of their rating. We limit ourselves to **Top 10** movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e3ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.223700e+04</td>\n",
       "      <td>42237.000000</td>\n",
       "      <td>42237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.872995e+05</td>\n",
       "      <td>303.150200</td>\n",
       "      <td>3.610318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.451020e+05</td>\n",
       "      <td>177.654595</td>\n",
       "      <td>1.063750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.170000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.004050e+05</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.186360e+05</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.502580e+05</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.644200e+06</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id       user_id        rating\n",
       "count  4.223700e+04  42237.000000  42237.000000\n",
       "mean   3.872995e+05    303.150200      3.610318\n",
       "std    6.451020e+05    177.654595      1.063750\n",
       "min    4.170000e+02      1.000000      0.500000\n",
       "25%    1.004050e+05    144.000000      3.000000\n",
       "50%    1.186360e+05    305.000000      4.000000\n",
       "75%    3.502580e+05    454.000000      4.500000\n",
       "max    6.644200e+06    610.000000      5.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b0d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(\n",
    "    labels, test_size=0.2, shuffle=True, stratify=labels.rating, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d37c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = Path(\"../data/intermediate\")\n",
    "target_dir.mkdir(exist_ok=True)\n",
    "train.to_csv(\"../data/intermediate/train.csv\", index=False)\n",
    "test.to_csv(\"../data/intermediate/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8b3da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1312\r\n",
      "-rw-r--r--  1 nirantk  staff  124049 Sep 24 19:56 test.csv\r\n",
      "-rw-r--r--  1 nirantk  staff  496384 Sep 24 19:56 train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {target_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b80e89bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109830, 111161, 110912, 102926, 133093, 108052, 112573, 107290, 76759, 112384]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "vc = dict(train.movie_id.value_counts())\n",
    "popular_movies = [k for k, v in vc.items()][:top_k]\n",
    "popular_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c1563",
   "metadata": {},
   "source": [
    "# How do we count a hit? \n",
    "\n",
    "1. We predict a list of Top K movies which the user should've rated\n",
    "2. If the user has infact seen ANY of the Top K moves, we get a hit, else a miss\n",
    "3. A mean across all users in target, is our hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a5a9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29853219696969696"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_hits(predicted_movies: List[int], seen_movies: List[int]):\n",
    "    return len(set(predicted_movies) & set(seen_movies)) > 0\n",
    "\n",
    "\n",
    "def calc_hit_rate(split):\n",
    "    hits = []\n",
    "    for user_id in split.user_id:\n",
    "        seen_movies = split[split.user_id == user_id].movie_id.unique()\n",
    "        hits.append(user_hits(popular_movies, seen_movies))\n",
    "\n",
    "    return sum(hits) / len(hits)\n",
    "\n",
    "\n",
    "calc_hit_rate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
